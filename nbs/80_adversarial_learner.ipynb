{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp vision.learner.adversary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Learner\n",
    "\n",
    "This requires *pytorch >= 1.3.1* due to a bug with fp16 argmax in lesser versions\n",
    "\n",
    "Note: Overhead is ~3x vanilla training (1x generate adversarial batch, 1x predict adversarial batch, 1x predict clean batch)\n",
    "\n",
    "The idea comes from this paper: https://arxiv.org/abs/1911.09665v1, and here we implement a variant of AdvProp with a dynamic attack strength\n",
    "using the Projected Gradient Descent attack and a moving epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import copy as cp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastcore.all import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.metrics import accuracy\n",
    "from fastai2.learner import *\n",
    "\n",
    "# PGD modified from https://towardsdatascience.com/know-your-enemy-7f7c5038bdf3\n",
    "def projected_gradient_descent(model, x, y, loss_fn, num_steps=1, step_size=1, step_norm='inf', eps=0.4, eps_norm='inf',\n",
    "                               clamp=None, y_target=None):\n",
    "    \"\"\"Performs the projected gradient descent attack on a batch of images.\"\"\"\n",
    "    x_adv = x.clone().detach().requires_grad_(True).to(x.device)\n",
    "    targeted = y_target is not None\n",
    "    num_channels = x.shape[1]\n",
    "    \n",
    "    # We need to generate adversarial examples with adversarial batch norm\n",
    "    model.set_bn_mode_aux()\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        _x_adv = x_adv.clone().detach()\n",
    "        \n",
    "        # apparently .requires_grad_(True) doesn't work??\n",
    "        _x_adv.requires_grad = True\n",
    "\n",
    "        prediction = model(_x_adv)\n",
    "        loss = loss_fn(prediction, y_target if targeted else y)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Force the gradient step to be a fixed size in a certain norm\n",
    "            if step_norm == 'inf':\n",
    "                gradients = _x_adv.grad.sign() * step_size\n",
    "            else:\n",
    "                # Note .view() assumes batched image data as 4D tensor\n",
    "                gradients = _x_adv.grad * step_size / _x_adv.grad.view(_x_adv.shape[0], -1)\\\n",
    "                    .norm(step_norm, dim=-1)\\\n",
    "                    .view(-1, num_channels, 1, 1)\n",
    "\n",
    "            if targeted:\n",
    "                # Targeted: Gradient descent with on the loss of the (incorrect) target label\n",
    "                # w.r.t. the image data\n",
    "                x_adv -= gradients\n",
    "            else:\n",
    "                # Untargeted: Gradient ascent on the loss of the correct label w.r.t.\n",
    "                # the model parameters\n",
    "                x_adv += gradients\n",
    "\n",
    "        # Project back into l_norm ball and correct range\n",
    "        if eps_norm == 'inf':\n",
    "            # Workaround as PyTorch doesn't have elementwise clip\n",
    "            x_adv = torch.max(torch.min(x_adv, x + eps), x - eps)\n",
    "        else:\n",
    "            delta = x_adv - x\n",
    "\n",
    "            # Assume x and x_adv are batched tensors where the first dimension is\n",
    "            # a batch dimension\n",
    "            mask = delta.view(delta.shape[0], -1).norm(norm, dim=1) <= eps\n",
    "\n",
    "            scaling_factor = delta.view(delta.shape[0], -1).norm(norm, dim=1)\n",
    "            scaling_factor[mask] = eps\n",
    "\n",
    "            # .view() assumes batched images as a 4D Tensor\n",
    "            delta *= eps / scaling_factor.view(-1, 1, 1, 1)\n",
    "\n",
    "            x_adv = x + delta\n",
    "            \n",
    "        # Only clamp if we request it\n",
    "        if clamp is not None:\n",
    "            x_adv = x_adv.clamp(*clamp)\n",
    "\n",
    "    return x_adv.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Attack():\n",
    "    ''' Basic attacker interface. '''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, model, x, y, loss, **kwargs):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PGDAttack(Attack):\n",
    "    def __init__(self, num_steps=1, step_size=1, step_norm='inf', eps=0.4, eps_norm='inf', clamp=(0, 1), y_target=None):\n",
    "        super(PGDAttack, self).__init__()\n",
    "        self.num_steps = num_steps\n",
    "        self.step_size = step_size\n",
    "        self.step_norm = step_norm\n",
    "        self.eps = eps\n",
    "        self.eps_norm = eps_norm\n",
    "        self.clamp = clamp\n",
    "        self.y_target = y_target\n",
    "        \n",
    "    def __call__(self, model, x, y, loss, *args, **kwargs):\n",
    "        return projected_gradient_descent(\n",
    "            model,\n",
    "            x,\n",
    "            y,\n",
    "            loss,\n",
    "            num_steps=self.num_steps,\n",
    "            step_size=self.step_size,\n",
    "            eps=self.eps,\n",
    "            eps_norm=self.eps_norm,\n",
    "            clamp=self.clamp,\n",
    "            y_target=self.y_target\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to patch `nn.Module` to have a flag for clean vs adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def set_bn_mode_clean(self:nn.Module):\n",
    "    self.training_mode = 0\n",
    "    for child in self.children():\n",
    "        child.set_bn_mode_clean()\n",
    "    \n",
    "@patch\n",
    "def set_bn_mode_aux(self:nn.Module):\n",
    "    self.training_mode = 1\n",
    "    for child in self.children():\n",
    "        child.set_bn_mode_aux()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a batchnorm layer which is toggleable between clean/aux modes\n",
    "\n",
    "TODO: Need to implement an inverse operation to \\_inject_aux_bns when exporting a model... we don't want to export this, but only the clean batch norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AuxBatchNorm(nn.Module):\n",
    "    def __init__(self, clean_bn, aux_bn):\n",
    "        super(AuxBatchNorm, self).__init__()\n",
    "        # Training modes: {clean: 0, aux: 1}\n",
    "        self.training_mode = 0\n",
    "        self.clean_bn = clean_bn\n",
    "        self.aux_bn = aux_bn\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Auxiliary is _only_ used when training against adv. examples, otherwise we use \n",
    "        # the clean batch norm.\n",
    "        if self.training and self.training_mode == 1:\n",
    "            return self.aux_bn(x)\n",
    "        return self.clean_bn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _inject_aux_bns(model, debug=False):\n",
    "    '''Replaces all batch norm layers in a pytorch model with an clean/auxiliary one'''\n",
    "    if debug:\n",
    "        print('Initial Model:', model)\n",
    "    def _inject(module):\n",
    "        # Recursively update the model\n",
    "        for child in module.children():\n",
    "            # Don't inject aux batchnorms\n",
    "            if isinstance(child, AuxBatchNorm):\n",
    "                if debug: print('Skipping Existing AuxBatchNorm')\n",
    "                return\n",
    "            _inject(child)\n",
    "            \n",
    "        # Do the replacement\n",
    "        for name, child in module.named_children():\n",
    "            # Note, we want to copy.deepcopy as we want to preserve the weights from pretraining, etc.\n",
    "            if isinstance(child, nn.BatchNorm1d):\n",
    "                if debug: print('Updating BatchNorm1d', name)\n",
    "                setattr(module, name, AuxBatchNorm(cp.deepcopy(child), cp.deepcopy(child)))\n",
    "            if isinstance(child, nn.BatchNorm2d):\n",
    "                if debug: print('Updating BatchNorm2d', name)\n",
    "                setattr(module, name, AuxBatchNorm(cp.deepcopy(child), cp.deepcopy(child)))\n",
    "            if isinstance(child, nn.BatchNorm3d):\n",
    "                if debug: print('Updating BatchNorm3d', name)\n",
    "                setattr(module, name, AuxBatchNorm(cp.deepcopy(child), cp.deepcopy(child)))\n",
    "    \n",
    "    _inject(model)\n",
    "    \n",
    "    if debug:\n",
    "        print('Injected Model:', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai2.data.all import *\n",
    "from fastai2.vision.all import *\n",
    "\n",
    "\n",
    "mnist = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "                 get_items=get_image_files, \n",
    "                 splitter=GrandparentSplitter(train_name='training', valid_name='testing'),\n",
    "                 get_y=parent_label)\n",
    "\n",
    "\n",
    "dbunch = mnist.dataloaders(untar_data(URLs.MNIST), bs=32, batch_tfms=[*aug_transforms(size=28, max_warp=0, do_flip=False), Normalize.from_stats(*mnist_stats)])\n",
    "dbunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.learner import *\n",
    "class DynamicPGD(Callback):\n",
    "    run_after=ProgressCallback\n",
    "    def __init__(self, *args, initial_eps=0.0001, target_adv_acc=0.95, eps_momentum=0.00001, eps_momentum_step=2, min_eps=0.00001, max_eps=0.5, **kwargs):\n",
    "        super(DynamicPGD, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        # What do we want the adversary accuracy to be relative to clean\n",
    "        # 0.5 -> aim for 50% of the adversaries correct vs clean (relative)\n",
    "        self.target_adv_acc = target_adv_acc\n",
    "        self.initial_eps = initial_eps\n",
    "        self.min_eps = min_eps\n",
    "        self.max_eps = max_eps\n",
    "        \n",
    "        # Epsilon momentum\n",
    "        self.eps_momentum_init = eps_momentum\n",
    "        self.eps_momentum = eps_momentum\n",
    "        self.eps_momentum_step = eps_momentum_step\n",
    "\n",
    "        # Momentum direction flag\n",
    "        self.prior_direction = 0\n",
    "\n",
    "        self.eps_history = []\n",
    "        self.adv_acc_history = []\n",
    "        self.adv_acc_rel_history = []\n",
    "        \n",
    "    def _reset(self):\n",
    "        assert isinstance(self.learn.attack, PGDAttack)\n",
    "        self.learn.attack.eps = self.initial_eps\n",
    "        self.eps_momentum = self.eps_momentum_init\n",
    "        \n",
    "        # Moving average buffers of size 10\n",
    "        self.moving_acc_adv = [0.0001] * 10\n",
    "        self.moving_acc_clean = [0.0001] * 10\n",
    "        \n",
    "        self.eps_history = []\n",
    "        self.adv_acc_history = []\n",
    "        self.adv_acc_rel_history = []\n",
    "        \n",
    "    def begin_fit(self):\n",
    "        self._reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        if self.learn.training and not self.learn.force_clean_mode:\n",
    "            # Update list of of recent clean/adv accuracies\n",
    "            adv_acc = accuracy(self.learn.pred_adv, self.learn.yb[0])\n",
    "            self.moving_acc_adv = self.moving_acc_adv[1:]\n",
    "            self.moving_acc_adv.append(adv_acc.item())\n",
    "            \n",
    "            clean_acc = accuracy(self.learn.pred, self.learn.yb[0])\n",
    "            self.moving_acc_clean = self.moving_acc_clean[1:]\n",
    "            self.moving_acc_clean.append(clean_acc.item())\n",
    "            \n",
    "            # Compute the moving averages\n",
    "            adv_average = np.mean(self.moving_acc_adv)\n",
    "            adv_target = np.mean(self.moving_acc_clean) * self.target_adv_acc\n",
    "\n",
    "            self.adv_acc_history.append(adv_average)\n",
    "            moving_mean = np.mean(self.moving_acc_clean)\n",
    "            if moving_mean > 0:\n",
    "                self.adv_acc_rel_history.append(adv_average / np.mean(self.moving_acc_clean))\n",
    "            else:\n",
    "                self.adv_acc_rel_history.append(0)\n",
    "                \n",
    "\n",
    "            if adv_average < adv_target:\n",
    "                if self.prior_direction != -1:\n",
    "                    self.eps_momentum = self.eps_momentum_init\n",
    "                else:\n",
    "                    self.eps_momentum *= self.eps_momentum_step\n",
    "                    \n",
    "                # Decrease FGSM strength\n",
    "                self.learn.attack.eps -= self.eps_momentum\n",
    "                self.prior_direction = -1\n",
    "                \n",
    "            if adv_average > adv_target:\n",
    "                if self.prior_direction != 1:\n",
    "                    self.eps_momentum = self.eps_momentum_init\n",
    "                else:\n",
    "                    self.eps_momentum *= self.eps_momentum_step\n",
    "                    \n",
    "                # Increase FGSM strength\n",
    "                self.learn.attack.eps += self.eps_momentum\n",
    "                self.prior_direction = 1\n",
    "                \n",
    "\n",
    "            # Always ensure a small amount of attack\n",
    "            # Clamp it between (0.01 ->  1) (since std of normalized data is 1)\n",
    "            self.learn.attack.eps = max(self.min_eps, self.learn.attack.eps)\n",
    "            self.learn.attack.eps = min(self.max_eps, self.learn.attack.eps)\n",
    "\n",
    "            self.eps_history.append(self.learn.attack.eps)\n",
    "            \n",
    "    def after_batch(self):\n",
    "        if hasattr(self.learn, 'progress'):\n",
    "            adv_average = np.mean(self.moving_acc_adv)\n",
    "            moving_acc_avg = np.mean(self.moving_acc_clean)\n",
    "            if moving_acc_avg > 0:\n",
    "                relacc = adv_average / moving_acc_avg\n",
    "                self.learn.progress.pbar.comment += f' -- strength {self.learn.attack.eps:.8f} -- rel acc {relacc:.4f}'\n",
    "            else:\n",
    "                self.learn.progress.pbar.comment += f' -- strength {self.learn.attack.eps:.8f} -- rel acc {0}'\n",
    "                \n",
    "            \n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots(3, 1, figsize=(10,10))\n",
    "        ax[0].set_title('PGD Epsilon')\n",
    "        ax[0].set_xlabel('Iteration')\n",
    "        ax[0].set_ylabel('Epsilon')\n",
    "        ax[0].plot(self.eps_history)\n",
    "        \n",
    "        ax[1].set_title('PGD Relative Accuracy')\n",
    "        ax[1].set_xlabel('Iteration')\n",
    "        ax[1].set_ylabel('accuracy to clean')\n",
    "        ax[1].plot(self.adv_acc_rel_history)\n",
    "        \n",
    "        ax[2].set_title('PGD Absolute Accuracy')\n",
    "        ax[2].set_xlabel('Iteration')\n",
    "        ax[2].set_ylabel('accuracy')\n",
    "        ax[2].plot(self.adv_acc_history)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdversarialLearner(Learner):\n",
    "    def __init__(self, *args, attack=None, debug=False, **kwargs):\n",
    "        super(AdversarialLearner, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        assert attack is not None\n",
    "        \n",
    "        self.attack = attack\n",
    "        self.debug = debug\n",
    "        \n",
    "#         if self.debug:\n",
    "#             self.fig, self.ax = plt.subplots(2,2)\n",
    "        \n",
    "        # Update batch norms to have auxiliary versions.\n",
    "        _inject_aux_bns(self.model)\n",
    "        \n",
    "        # Flag to disable adversary training\n",
    "        self.force_clean_mode = False\n",
    "        \n",
    "    def disable_adversary(self):\n",
    "        self.force_clean_mode = True\n",
    "        \n",
    "    def enable_adversary(self):\n",
    "        self.force_clean_mode = False\n",
    "        \n",
    "    def one_batch(self, i, b):\n",
    "        ''' Modified one_batch to use AdvProp from paper: https://arxiv.org/abs/1911.09665v1'''\n",
    "        if self.model.training and not self.force_clean_mode:\n",
    "            self.iter = i\n",
    "            try:\n",
    "                self._split(b);                                 \n",
    "                self('begin_batch')\n",
    "                \n",
    "                # Generate adversarial examples from batch, using epsilon and PGD attacker\n",
    "                self.adv_xb = self.attack(self.model, self.xb[0], self.yb[0], self.loss_func)\n",
    "                \n",
    "#                 if self.debug and self.iter % 10000 == 0:\n",
    "#                     example = self.adv_xb[0].detach().cpu().permute(1,2,0)\n",
    "#                     example2 = self.adv_xb[1].detach().cpu().permute(1,2,0)\n",
    "#                     # top 2 rows are our generated images\n",
    "#                     self.ax[0][0].imshow(example)\n",
    "#                     self.ax[0][1].imshow(example2)\n",
    "#                     # bottom 2 rows are real examples\n",
    "#                     self.ax[1][0].imshow(self.xb[0][0].detach().cpu().permute(1,2,0))\n",
    "#                     self.ax[1][1].imshow(self.xb[0][1].detach().cpu().permute(1,2,0))\n",
    "#                     self.fig.canvas.draw()\n",
    "#                     display(self.fig)\n",
    "\n",
    "\n",
    "                # Zero grad since generation creates gradients\n",
    "                self.opt.zero_grad()\n",
    "\n",
    "                # Toggle batch norm layers to use auxiliary weights\n",
    "                self.model.set_bn_mode_aux()\n",
    "                \n",
    "                # Make predictions on adversaries\n",
    "                self.pred_adv = self.model(self.adv_xb)\n",
    "                \n",
    "                # Set batch norm layers to use clean weights\n",
    "                self.model.set_bn_mode_clean()\n",
    "                \n",
    "                # Make predictions on clean examples\n",
    "                self.pred = self.model(*self.xb)\n",
    "                self('after_pred')\n",
    "                if len(self.yb) == 0: return\n",
    "\n",
    "                # Compute loss on adveraries\n",
    "                self.model.set_bn_mode_aux()\n",
    "                self.loss_adv = self.loss_func(self.pred_adv, *self.yb)\n",
    "                \n",
    "                # Compute loss on clean\n",
    "                self.model.set_bn_mode_clean()\n",
    "                self.loss = self.loss_func(self.pred, *self.yb)\n",
    "                self('after_loss')\n",
    "                if not self.training: return\n",
    "                \n",
    "                # Combine the loss Ladv + Lclean\n",
    "                self.combined_loss = self.loss_adv + self.loss\n",
    "                self.combined_loss.backward();                   self('after_backward')\n",
    "                self.opt.step();                                 self('after_step')\n",
    "            except CancelBatchException:                         self('after_cancel_batch')\n",
    "            finally:                                             self('after_batch')\n",
    "        else:\n",
    "            # Ensure we're only using the clean mode here.\n",
    "            self.model.set_bn_mode_clean()\n",
    "            super().one_batch(i, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='503' class='' max='1875', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      26.83% [503/1875 00:10<00:27 0.6603 -- strength 0.01780396 -- rel acc 0.9464]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai2.metrics import *\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(LeNet, self).__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(3, 5, (5,5), padding=2)\n",
    "\t\tself.conv2 = nn.Conv2d(5, 10, (5,5))\n",
    "\t\tself.fc1   = nn.Linear(10*5*5, 50)\n",
    "\t\tself.fc2   = nn.Linear(50, 10)\n",
    "\tdef forward(self, x):\n",
    "\t\tx = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "\t\tx = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "\t\tx = x.view(-1, self.num_flat_features(x))\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\tx = self.fc2(x)\n",
    "\t\treturn x\n",
    "\tdef num_flat_features(self, x):\n",
    "\t\tsize = x.size()[1:]\n",
    "\t\tnum_features = 1\n",
    "\t\tfor s in size:\n",
    "\t\t\tnum_features *= s\n",
    "\t\treturn num_features\n",
    "    \n",
    "test_baseline = AdversarialLearner(dbunch, model=LeNet(), loss_func=F.cross_entropy, metrics=[accuracy], attack=PGDAttack(), debug=True)\n",
    "test_baseline.add_cbs(DynamicPGD(eps_momentum_step=1.03, max_eps=0.5, target_adv_acc=0.95))\n",
    "\n",
    "test_baseline.fit_one_cycle(3, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.119473</td>\n",
       "      <td>0.083755</td>\n",
       "      <td>0.973500</td>\n",
       "      <td>00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.065184</td>\n",
       "      <td>0.041887</td>\n",
       "      <td>0.986300</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.045111</td>\n",
       "      <td>0.033128</td>\n",
       "      <td>0.989400</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_baseline_nopgd = Learner(dbunch, model=LeNet(), loss_func=F.cross_entropy, metrics=[accuracy])\n",
    "test_baseline_nopgd.fit_one_cycle(3, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
